# -*- coding: utf-8 -*-
"""Submission Sistem Rekomendasi Nurul Tazkiyah .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18gseCzkQadKm_jEV3Sym0PXV0FSI4zQP

# Proyek Movie Recommendation Nurul Tazkiyah Adam

# **1. Data Understanding**

## Import Library
"""

# Commented out IPython magic to ensure Python compatibility.
import zipfile
import tensorflow as tf
import pandas as pd
import numpy as np
import seaborn as sns
from tensorflow import keras
from tensorflow.keras import layers
import matplotlib.pyplot as plt
# %matplotlib inline
from keras.callbacks import EarlyStopping
from google.colab import files
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

"""## Download Dataset

dataset yang digunakan pada proyek ini bisa diakses melalui [tautan ini ](kaggle.com/datasets/rohan4050/movie-recommendation-data).
"""

!pip install -q kaggle

uploaded = files.upload()

!chmod 600 /content/kaggle.json

! KAGGLE_CONFIG_DIR=/content/ kaggle datasets download -d rohan4050/movie-recommendation-data

local_zip = '/content/movie-recommendation-data.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/content')
zip_ref.close()

"""dalam dataset terdapat 


*   folder ml-latest-small, dengan isi file:
    - links.csv
    - movies.csv
    - ratings.csv
    - tags.csv
*   file movies_metadata.csv

namun pada proyek ini hanya akan menggunakan file `movies.csv` dan `ratings.csv`

## Univariate Exploratory Data Analysis
"""

movies = pd.read_csv('/content/ml-latest-small/movies.csv')
ratings = pd.read_csv('/content/ml-latest-small/ratings.csv')

print(f'Jumlah data movies sebanyak {movies.shape[0]}')
print(f'Jumlah variabel pada data movies sebanyak {movies.shape[1]} variabel')
print(f'Jumlah data ratings sebanyak {ratings.shape[0]}')
print(f'Jumlah variabel pada data ratings sebanyak {ratings.shape[1]} variabel')

"""### **Dataset Movies**"""

movies.head()

"""Variable dataset movies terbagi 3 yakni:
- `movieId` -> ID film
- `title` -> Judul film
- `genres` -> Genre film

dengan detail tipe data sebagai berikut


"""

movies.info()

print(f'Cek Missing Value Pada Variable Dataset Movies:')
print(f'- movieId sebanyak {movies.movieId.isnull().sum()}')
print(f'- title sebanyak {movies.title.isnull().sum()}')
print(f'- movieId sebanyak {movies.genres.isnull().sum()}')

print(f'Cek Duplikasi Dataset Movies: {movies.duplicated().sum()} duplikasi')

print(f'Cek Data Unique Pada Variable Dataset Movies:')
print(f'- movieId sebanyak {movies.movieId.nunique()}')
print(f'- title sebanyak {movies.title.nunique()}')
print(f'- movieId sebanyak {movies.genres.nunique()}')

"""### **Dataset Ratings**"""

ratings.head()

"""Variable dataset ratings terbagi 4 yakni:
- `userId` -> ID User pemberi rating
- `movieId` -> ID film yang dirating
- `rating` -> Rating film yang diberikan user
- `timestamp` -> Waktu rating terekam

dengan detail tipe data sebagai berikut
"""

ratings.info()

ratings.describe()

"""setelah dicek, didapatkan informasi skala dari rating film yakni rating 0,5 sampai rating 5."""

print(f'Cek Missing Value Pada Variable Dataset Ratings:')
print(f'- userId sebanyak {ratings.userId.isnull().sum()}')
print(f'- movieId sebanyak {ratings.movieId.isnull().sum()}')
print(f'- rating sebanyak {ratings.rating.isnull().sum()}')
print(f'- timestamp sebanyak {ratings.timestamp.isnull().sum()}')

print(f'Cek Duplikasi Dataset Ratings: {ratings.duplicated().sum()} duplikasi')

print(f'Cek Data Unique Pada Variable Dataset Ratings:')
print(f'- userId sebanyak {ratings.userId.nunique()}')
print(f'- movieId sebanyak {ratings.movieId.nunique()}')
print(f'- rating sebanyak {ratings.rating.nunique()}')
print(f'- timestamp sebanyak {ratings.timestamp.nunique()}')

"""# **2. Data Preparation**

## Pembersihan Missing Value
"""

movies.dropna(axis=0, inplace=True)
ratings.dropna(axis=0, inplace=True)

"""## Sorting Data Rating Berdasarkan User ID Kemudian Menjadikan integer"""

ratings = ratings.sort_values('userId').astype('int')

"""## Pembersihan Duplikasi Data """

movies.drop_duplicates(subset=['title'], keep='first', inplace=True)
ratings.drop_duplicates(subset=['userId','movieId'], keep='first', inplace=True)

"""## Penggabungan Dataset"""

merge_dataset = pd.merge(ratings, movies, how='left', on='movieId')
movierating = merge_dataset.copy().drop('timestamp', axis=1)
movierating.head()

"""menghapus missing values setelah dataset digabungkan"""

movierating = movierating[~pd.isnull(movierating['genres'])]

print(f'Setelah menggabungkan dataset dan menghapus missing values didapatkan sebanyak:')
print(f'- {movierating.shape[0]} baris data')
print(f'- {movierating.shape[1]} kolom / variable')

"""# **3. Model Development**

- # **Content Based Filtering**

**TF- IDF Vectorizer** 
melakukan inisialisasi TfidfVectorizer, kemudian perhitungan idf pada data film dan melakukan array dari fitur index integer ke fitur nama
"""

tfid = TfidfVectorizer(stop_words='english')
tfid.fit(movies['genres'])
tfid.get_feature_names()

"""**Transform Data Film Pada Kolom Genres ke bentuk vektor Matrix**"""

tfidf_matrix = tfid.fit_transform(movies['genres']) 
tfidf_matrix.shape

"""**Menghitung Cosine Similarity**"""

cosim = cosine_similarity(tfidf_matrix)
cosim

"""**Dataframe baru berdasarkan Cosine Similarity**"""

cosim_df = pd.DataFrame(cosim, index=movies['title'], columns=movies['title'])
print('Shape:', cosim_df.shape)
cosim_df.sample(10, axis=1).sample(10, axis=0)

"""dari hasil diatas didapatkan similarity matrix pada setiap film

## **Test Model Recommendation Content Based Filtering**

pendefinisian fungsi movie_recom untuk menampilkan hasil rekomendasi film berdasarkan kesamaan genre dari satu judul film
"""

def movie_recom(movies_title, 
                         similarity_data=cosim_df, 
                         items=movies[['movieId','title','genres']],
                         k=10):
   
    index = similarity_data.loc[:, movies_title].to_numpy().argpartition(
        range(-1, -k, -1)
    )

    closest = similarity_data.columns[index[-1:-(k+2):-1]]

    closest = closest.drop(movies_title, errors='ignore')

    return pd.DataFrame(closest).merge(items).head(k)

find_movie = movies[movies['title'] == 'American History X (1998)']
find_movie

movie_title = 'American History X (1998)'
movie_recomend = movie_recom(movie_title)
movie_recomend

"""Hasil uji rekomendasi di atas berhasil. Dapat dilihat bahwa sistem yang telah dirancang memberikan rekomendasi 10 judul film yang sesuai berdasarkan genre yang sama dengan satu judul film yang dipilih. Pada kasus ini menggunakan sample film *American History X (1998)* yang memiliki genre Crime dan Drama.

- # **Collaborative Filtering**

**Proses encoding fitur userId pada dataset menjadi array**


mengubah unique user id menjadi list, kemudian encoding User ID, lalu mengubah encoding angka ke userID
"""

user_id = movierating['userId'].unique().tolist()
 
user_to_user_encoded = {x: i for i, x in enumerate(user_id)}
 
user_encoded_to_user = {i: x for i, x in enumerate(user_id)}

"""**Proses encoding fitur movieId pada dataset  menjadi array**

mengubah unique  movie id menjadi list, kemudian encoding movie ID, lalu mengubah encoding angka ke movieID
"""

movie_id = movierating['movieId'].unique().tolist()
 
movie_to_movie_encoded = {x: i for i, x in enumerate(movie_id)}
 
movie_encoded_to_movie = {i: x for i, x in enumerate(movie_id)}

"""**Mapping User ID ke dataframe user dan Movie ID ke dataframe movie**"""

movierating['user'] = movierating['userId'].map(user_to_user_encoded)
movierating['movie'] = movierating['movieId'].map(movie_to_movie_encoded)
movierating.head()

num_users = len(user_to_user_encoded)
print(f'Jumlah Pengguna Sebanyak {num_users}')

num_movie = len(movie_encoded_to_movie)
print(f'Jumlah Movie Sebanyak {num_movie}')

movierating['rating'] = movierating['rating'].values.astype(np.float32)

min_rating = min(movierating['rating'])
print(f'Nilai Rating Terkecil: {min_rating}')

max_rating = max(movierating['rating'])
print(f'Nilai Rating Terbesar: {max_rating}')

"""### **Pembagian Data Training dan Validasi**

mengacak dataset
"""

movierating = movierating.sample(frac=1, random_state=42)
movierating.head()

"""mendeklarasikan x untuk mencocokkan data pengguna dan film menjadi satu value, lalu mendeklarasikan y untuk rating dari hasil, selanjutnya membagi dataset dengan skala data **training 80% dan validasi 20%**"""

x = movierating[['user', 'movie']].values
y = movierating['rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values
train_indices = int(0.8 * movierating.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)

"""### **Melatih Model**

Pembuatan Kelas dan Inisialisasi Fungsi
"""

class RecommenderNet(tf.keras.Model):
  def __init__(self, num_users, num_movie, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_movie = num_movie
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding(
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(5e-7)
    )
    self.user_bias = layers.Embedding(num_users, 1)
    self.movie_embedding = layers.Embedding(
        num_movie,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(5e-7)
    )
    self.movie_bias = layers.Embedding(num_movie, 1)
 
  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0])
    user_bias = self.user_bias(inputs[:, 0])
    movie_vector = self.movie_embedding(inputs[:, 1])
    movie_bias = self.movie_bias(inputs[:, 1])
 
    dot_user_movie = tf.tensordot(user_vector, movie_vector, 2) 
 
    x = dot_user_movie + user_bias + movie_bias
    
    return tf.nn.sigmoid(x)

#memanggil kelas
model = RecommenderNet(num_users, num_movie, 50) 

#mengcompile model
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[[tf.keras.metrics.MeanAbsoluteError(),tf.keras.metrics.RootMeanSquaredError()]]
)

#callback
iniCallbacks = EarlyStopping(
    min_delta=0.0001,
    patience=7,
    restore_best_weights=True,
)

history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 64,
    epochs = 100,
    validation_data = (x_val, y_val),
    callbacks=[iniCallbacks]
)

"""### **Test Model Recommedation Collaborative Filtering**

Mengambil Datasampel Pengguna
"""

user_ID = movierating.userId.sample(1).iloc[0]
movie_watched_by_user = movierating[movierating.userId == user_ID]
 
movie_not_watched = movies[~movies['movieId'].isin(movie_watched_by_user.movieId.values)]['movieId'] 
movie_not_watched = list(
    set(movie_not_watched)
    .intersection(set(movie_to_movie_encoded.keys()))
)

 
movie_not_watched = [[movie_to_movie_encoded.get(x)] for x in movie_not_watched]
user_encoder = user_to_user_encoded.get(user_ID)
user_movie_array = np.hstack(
    ([[user_encoder]] * len(movie_not_watched), movie_not_watched)
)

ratings = model.predict(user_movie_array).flatten()
 
top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_movie_ids = [
    movie_encoded_to_movie.get(movie_not_watched[x][0]) for x in top_ratings_indices
]

print('Hasil Rekomendasi Berdasarkan Model Collaborative Filtering')
print('====' * 15) 
print(f'Rekomendasi Untuk User dengan ID {(user_ID)} (dipilih secara acak)')
print('====' * 15)
print(f'5 Movie dengan Rating Tertinggi dari user {(user_ID)}')
print('----' * 10)
 
top_movie_user = (
    movie_watched_by_user.sort_values(
        by = 'rating',
        ascending=False
    )
    .head(5)
    .movieId.values
)
 
movie_df_rows = movies[movies['movieId'].isin(top_movie_user)]
for row in movie_df_rows.itertuples():
    print(row.title, ':', row.genres)
 
print('====' * 15)
print(f'Untuk itu, Top 10 Rekomendasi Movie untuk user {(user_ID)} adalah berikut')
print('----' * 10)
 
recommended_movie = movies[movies['movieId'].isin(recommended_movie_ids)]
for row in recommended_movie.itertuples():
    print(row.title, ':', row.genres)

"""# **4. Evaluation**

Evaluasi menggunakan **Mean Absolute Error (MAE)** dan **Root Mean Squared Error (RMSE)** pada Collaborative Filtering dan Precision Content Based Filtering

**Mengecek Precision Metrik**
"""

find_movie = movies[movies['title'] == 'Toy Story (1995)']
find_movie

"""dapat dilihat film **Toy Story (1995)** memiliki 4 Genre yakni Adventure, Animation, Children, Comedy, dan Fantasy. Kemudian, kita akan melihat apakah rekomendasi akan sesuai 100% melalui langkah berikut ini"""

movie_title = 'Toy Story (1995)'
movie_recomend = movie_recom(movie_title)
movie_recomend

"""dari hasil tersebut didapatkan **9 dari 10 Film** mendapatkan rekomendasi genre yang sama (similar) dengan 4 kategori genre pada film **Toy Story (1995)**. Sehingga, dapat dikatakan **Precision Sistem yang telah dirancang pada proyek ini sebesar 90%**

## **Visualisasi Mean Absolute Error**
"""

plt.plot(history.history['mean_absolute_error'])
plt.plot(history.history['val_mean_absolute_error'])
plt.title('model_metrics')
plt.ylabel('mean_absolute_error')
plt.xlabel('epoch')
plt.legend(['mean_absolute_error', 'val_mean_absolute_error'])
plt.show()

"""## **Visualisasi Root Mean Squared Error**"""

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['root_mean_squared_error', 'val_root_mean_squared_error'])
plt.show()